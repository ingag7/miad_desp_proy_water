# -*- coding: utf-8 -*-
"""water_potability_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uw-tPJ8QnKSCVWdBLxTIfZvdHEYnxOJq

# **Proyecto de Análisis sobre la Potabilidad del Agua**
## MIAD - Despliegue de Soluciones Analíticas
### Carlos Galindo Aguilera, 2024

### **1. Importar Librerías**
"""

# Exploración de datos
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Preprocesamiento de datos
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from imblearn.over_sampling import SMOTE

# Implementación de modelos
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, roc_auc_score

#Tablero
import gradio as gr
import numpy as np

!pip install dash
!pip install flask-ngrok

"""### **2. Extraer datos**"""

water_data = pd.read_csv('/content/data/water_potability.csv')
water_data.head()

"""### **3. Exploración de los datos**


El dataset tiene 3,276 registros y 10 columnas.
Variables de tipo float64 y una variable de tipo int64 (Potability), siendo esta la variable de respuesta.

* Valores nulos:

  Existen valores nulos en las siguientes columnas:
  ph: 491 valores nulos.
  Sulfate: 781 valores nulos.
  Trihalomethanes: 162 valores nulos.

* Estadísticas descriptivas:

  ph: Rango de 0 a 14, con una media de ~7.08.
  Hardness y Solids: Sin valores nulos, lo cual es positivo para la integridad de estas variables.
  Potabilidad (Potability): Es la variable de respuesta y esta codificada como 0 y 1, por lo que lo desarrollaremos como un problema de clasificación.
"""

# Inspección inicial
data_info = water_data.info()
data_head = water_data.head()
data_describe = water_data.describe()

# Revisar valores nulos en el dataset
missing_values = water_data.isnull().sum()

data_info, data_head, data_describe, missing_values

"""### **4. Gráficos de exploración de datos**

* Histogramas de las variables numéricas:

  En general las distribuciones se muestran uniformes, posiblemente las variables Solids y Conductivity, muestran sesgos, lo cual podría influir en el modelo predictivo.

* Gráficos de dispersión

  ph vs Hardness:
  En este gráfico, aunque hay mucha superposición, hay algunos patrones interesantes. Los valores de ph y Hardness no muestran una separación clara por Potability, pero sí cierta tendencia de concentración en ciertos rangos de ph (~6-8).

* Mapa de calor de correlación

  Todas las correlaciones son bajas y cercanas a cero, esto indica que las variables en el dataset son prácticamente independientes entre sí. La falta de correlación sugiere que las variables no están directamente relacionadas entre sí y aportan información única al dataset. Esto podría ser útil para modelos de aprendizaje supervisado, ya que cada variable representa características independientes del agua, aumentando la variedad de patrones para la clasificación.
"""

# 1. Histograma de las variables numéricas
water_data.hist(bins=15, figsize=(15, 10), edgecolor="black")
plt.suptitle("Histograms of Numerical Variables", fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])

# 2. Gráficos de dispersión entre algunas variables clave, coloreados por 'Potability'
plt.figure(figsize=(12, 8))
sns.scatterplot(data=water_data, x='ph', y='Hardness', hue='Potability', palette='viridis', alpha=0.6)
plt.title("Scatter Plot of ph vs Hardness by Potability")

plt.figure(figsize=(12, 8))
sns.scatterplot(data=water_data, x='Chloramines', y='Organic_carbon', hue='Potability', palette='viridis', alpha=0.6)
plt.title("Scatter Plot of Chloramines vs Organic Carbon by Potability")

# 3. Mapa de calor de correlación
plt.figure(figsize=(10, 8))
corr_matrix = water_data.corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Heatmap of Correlation Matrix")

plt.show()

"""### **5. Preprocesamiento de datos**

Se realiza el preprocesamiento de los datos con los siguientes pasos:

*Imputación de valores nulos:* Los valores faltantes en cada columna se imputaron utilizando la media de cada variable.

*Normalización:* Los datos se escalaron al rango [0, 1] para asegurar que todas las características tengan el mismo rango y facilitar la interpretación en modelos que requieren datos en un intervalo específico.

*Selección de variables:* Al ser un dataset tan pequeño se decidió usar todas las variables (9). Esto permite evitar perdida de información pues eliminar características podría eliminar patrones útiles. Además, algunas variables pueden parecer poco importantes por sí solas pero ser clave en combinación con otras. En todo caso, algoritmos como Random Forest o XGBoost manejan bien conjuntos de datos con muchas características y pueden identificar automáticamente las más relevantes.
"""

# Separar los datos de entrada y la variable de salida
X = water_data.drop('Potability', axis=1)
y = water_data['Potability']

# Imputación de valores nulos usando la media
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

# Normalización de los datos a un rango de [0, 1]
scaler_minmax = MinMaxScaler()
X_normalized = scaler_minmax.fit_transform(X_imputed)

"""### **6. Implementación de Modelos Predictivos**

Dadas las condiciones de los datos se implementan 6 distintos modelos de clasificación con el fín de encontrar el más idoneo dentro del contexto que busca identificar si una fuente hídrica es o no potable.

Dicho esto implementaremos los siguientes modelos:

* Regresión Logística
* Random Forest Classifier
* XGBoost Classifier
* SVC
* Gradient Boosting Classifier
* K-Neighbors Classifier

A su vez usaremos el score y el ROC AUC como métricas base para medir su desempeño.

#### **6.1. Regresión Logística**
"""

# Dividir datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42, stratify=y)

# Entrenar modelo con ponderación de clases
LogReg = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')
LogReg.fit(X_train, y_train)

# Predicciones y métrica
y_pred_LR = LogReg.predict(X_test)

# Score
LR_score = round(LogReg.score(X_test, y_test), 3)
print('LogReg Score: {}'.format(LR_score))

# ROC AUC
LR_roc_auc = roc_auc_score(y_test, LogReg.predict_proba(X_test)[:, 1])
print(f"LogReg ROC AUC: {LR_roc_auc:.3f}")

"""#### **6.2. Random Forest**"""

# Entrenar un modelo de Random Forest
RF = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100)
RF.fit(X_train, y_train)

# Predicciones y métrica
y_pred_RF = RF.predict(X_test)

# Score
RF_score = round(RF.score(X_test, y_test), 3)
print('RF Score: {}'.format(RF_score))

# ROC AUC
RF_roc_auc = roc_auc_score(y_test, RF.predict_proba(X_test)[:, 1])
print(f"RF ROC AUC: {RF_roc_auc:.3f}")

"""#### **6.3. XGBoost**"""

# Entrenar modelo XGBoost
XGB = XGBClassifier(random_state=42, scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]))
XGB.fit(X_train, y_train)

# Predicciones
y_pred_XGB = XGB.predict(X_test)

# Score
XGB_score = round(XGB.score(X_test, y_test), 3)
print('XGBoost Score: {}'.format(XGB_score))

# ROC AUC
XGB_roc_auc = roc_auc_score(y_test, XGB.predict_proba(X_test)[:, 1])
print(f"XGB ROC AUC: {XGB_roc_auc:.3f}")

"""#### **6.4. SVC**"""

from sklearn.svm import SVC

# Entrenar modelo SVM
SVM = SVC(random_state=42, probability=True, class_weight='balanced')
SVM.fit(X_train, y_train)

# Predicciones
y_pred_SVM = SVM.predict(X_test)

# Score
SVM_score = round(SVM.score(X_test, y_test), 3)
print('SVM Score: {}'.format(SVM_score))

# ROC AUC
SVM_roc_auc = roc_auc_score(y_test, SVM.predict_proba(X_test)[:, 1])
print(f"SVM ROC AUC: {SVM_roc_auc:.3f}")

"""#### **6.5. GradientBoosting**"""

from sklearn.ensemble import GradientBoostingClassifier

# Entrenar modelo GBM
GBM = GradientBoostingClassifier(random_state=42)
GBM.fit(X_train, y_train)

# Predicciones
y_pred_GBM = GBM.predict(X_test)

# Score
GBM_score = round(GBM.score(X_test, y_test), 3)
print('GBM Score: {}'.format(GBM_score))

# ROC AUC
GBM_roc_auc = roc_auc_score(y_test, GBM.predict_proba(X_test)[:, 1])
print(f"GBM ROC AUC: {GBM_roc_auc:.3f}")

"""#### **6.6. K-Neighbors**"""

from sklearn.neighbors import KNeighborsClassifier

# Entrenar modelo KNN
KNN = KNeighborsClassifier(n_neighbors=5)
KNN.fit(X_train, y_train)

# Predicciones
y_pred_KNN = KNN.predict(X_test)

# Score
KNN_score = round(KNN.score(X_test, y_test), 3)
print('KNN Score: {}'.format(KNN_score))

# ROC AUC
KNN_roc_auc = roc_auc_score(y_test, KNN.predict_proba(X_test)[:, 1])
print(f"KNN ROC AUC: {KNN_roc_auc:.3f}")

"""### **7. Métricas**
Los modelos se evaluan con base en dos métricas: el score (accuracy) y el ROC AUC.

El objetivo de usar estas métricas es evaluar los modelos de clasificación desde diferentes aspectos del desempeño.

Con el score queremos medir proporción de predicciones correctas sobre el total de predicciones, mientras que con el ROC AUC se busca medir la capacidad del modelo para distinguir entre clases y a su vez complementar al score al medir qué tan bien el modelo separa las clases y captura el desempeño en escenarios de datos desbalanceados.

#### **7.1. Score**

* Random Forest (0.669) y Gradient Boosting (0.659) presentan los mejores scores, indicando que estos modelos tuvieron el mayor porcentaje de predicciones correctas.

* Regresión Logística (0.530) tiene el menor score, probablemente debido a su simplicidad y falta de capacidad para capturar relaciones no lineales complejas.
"""

# Resultados de todos los modelos
models = ['Logistic Regression', 'Random Forest', 'XGBoost', 'SVM', 'Gradient Boosting', 'KNN']
scores = [LR_score, RF_score, XGB_score, SVM_score, GBM_score, KNN_score]

# Crear un DataFrame para ordenar los resultados
scores_df = pd.DataFrame({"Model": models, "Score": scores}).sort_values(by="Score", ascending=False)

# Graficar los resultados ordenados
plt.figure(figsize=(10, 6))
plt.bar(scores_df["Model"], scores_df["Score"], color=['blue', 'green', 'orange', 'purple', 'red', 'cyan'])
plt.ylim(0, 1)  # Escalar de 0 a 1 para las métricas
plt.title('Comparación de Desempeño entre Modelos (Score)')
plt.xlabel('Modelos')
plt.ylabel('Score')
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Mostrar valores en las barras
for i, score in enumerate(scores_df["Score"]):
    plt.text(i, score + 0.02, f"{score:.3f}", ha='center', fontsize=10, color='black')

plt.show()

"""#### **7.2. ROC AUC**
* Gradient Boosting y Random Forest obtuvieron el mejor ROC AUC (0.664), lo que sugiere que estos modelos tienen la mejor capacidad para distinguir entre clases.

* KNN (0.577) y Regresión Logística (0.549) tienen los valores más bajos de ROC AUC, indicando una menor capacidad para separar las clases.
"""

# Resultados de todos los modelos
models = ['Logistic Regression', 'Random Forest', 'XGBoost', 'SVM', 'Gradient Boosting', 'KNN']
scores = [LR_roc_auc, RF_roc_auc, XGB_roc_auc, SVM_roc_auc, GBM_roc_auc, KNN_roc_auc]

# Crear un DataFrame para ordenar los resultados
scores_df = pd.DataFrame({"Model": models, "Score": scores}).sort_values(by="Score", ascending=False)

# Graficar los resultados ordenados
plt.figure(figsize=(10, 6))
plt.bar(scores_df["Model"], scores_df["Score"], color=['blue', 'green', 'orange', 'purple', 'red', 'cyan'])
plt.ylim(0, 1)  # Escalar de 0 a 1 para las métricas
plt.title('Comparación de Desempeño entre Modelos (ROC AUC)')
plt.xlabel('Modelos')
plt.ylabel('ROC AUC')
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Mostrar valores en las barras
for i, score in enumerate(scores_df["Score"]):
    plt.text(i, score + 0.02, f"{score:.3f}", ha='center', fontsize=10, color='black')

plt.show()

"""### **8. Revisión de balanceo de clases**"""

# Crear un DataFrame para contar las clases
class_counts = y.value_counts()

# Crear un gráfico de pastel (pie chart) para mostrar la distribución de las clases
plt.figure(figsize=(6, 6))
plt.pie(class_counts.values, labels=["No Potable", "Potable"], autopct='%1.1f%%', startangle=90, colors=["skyblue", "lightgreen"])
plt.title("Distribución de Clases en el Dataset")
plt.axis('equal')  # Asegura que el gráfico sea un círculo
plt.show()

"""### **9. Tablero**"""

# Obtener la importancia de las características
feature_importances = RF.feature_importances_
feature_names = water_data.drop("Potability", axis=1).columns

# Crear un DataFrame para mostrar la importancia
importance_df = pd.DataFrame({
    "Feature": feature_names,
    "Importance": feature_importances
}).sort_values(by="Importance", ascending=False)

# Mostrar las importancias
print(importance_df)

import matplotlib.pyplot as plt
import pandas as pd

# Datos reales de importancia de características
importance_data = {
    "Feature": ["pH", "Sulfate", "Hardness", "Chloramines", "Solids", "Turbidity", "Conductivity", "Organic Carbon", "Trihalomethanes"],
    "Importance": [0.131225, 0.123103, 0.117468, 0.116345, 0.116081, 0.101077, 0.100291, 0.097330, 0.097080]
}
importance_df = pd.DataFrame(importance_data).sort_values(by="Importance", ascending=False)

# Métricas de desempeño de modelos
metrics_data = {
    "Model": ["Random Forest", "Gradient Boosting", "XGBoost", "SVM", "KNN", "Logistic Regression"],
    "Accuracy": [0.669, 0.659, 0.623, 0.614, 0.607, 0.530],
    "ROC AUC": [0.664, 0.664, 0.614, 0.635, 0.577, 0.549]
}
metrics_df = pd.DataFrame(metrics_data)

# Balance de clases
class_counts = {"No Potable": 61, "Potable": 39}

# Crear las gráficas
plt.figure(figsize=(15, 10))

# Gráfica 1: Balance de Clases
plt.subplot(2, 2, 1)
plt.pie(class_counts.values(), labels=class_counts.keys(), autopct='%1.1f%%', startangle=90, colors=["skyblue", "lightgreen"])
plt.title("Distribución de Clases")

# Gráfica 2: Comparación de Modelos (Accuracy)
plt.subplot(2, 2, 2)
plt.bar(metrics_df["Model"], metrics_df["Accuracy"], color="lightcoral")
plt.title("Comparación de Modelos - Accuracy")
plt.ylabel("Accuracy")
plt.xticks(rotation=45)

# Gráfica 3: Comparación de Modelos (ROC AUC)
plt.subplot(2, 2, 3)
plt.bar(metrics_df["Model"], metrics_df["ROC AUC"], color="mediumseagreen")
plt.title("Comparación de Modelos - ROC AUC")
plt.ylabel("ROC AUC")
plt.xticks(rotation=45)

# Gráfica 4: Importancia de Características
plt.subplot(2, 2, 4)
plt.barh(importance_df["Feature"], importance_df["Importance"], color="dodgerblue")
plt.title("Importancia de las Características")
plt.xlabel("Importancia")
plt.ylabel("Características")
plt.gca().invert_yaxis()  # Invertir el orden para mostrar las más importantes primero

plt.tight_layout()
plt.show()

